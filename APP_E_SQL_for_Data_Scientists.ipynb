{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Appendix E -- SQL for Data Scientists\n## *Python for AI/ML: A Complete Learning Journey*\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timothy-watt/python-for-ai-ml/blob/main/APP_E_SQL_for_Data_Scientists.ipynb)\n&nbsp;&nbsp;[![Back to TOC](https://img.shields.io/badge/Back_to-Table_of_Contents-1B3A5C?style=flat-square)](https://colab.research.google.com/github/timothy-watt/python-for-ai-ml/blob/main/Python_for_AIML_TOC.ipynb)\n\n---\n\n**Prerequisites:** Chapter 3 (NumPy and Pandas)  \n\n### Learning Objectives\n\n- Create and query a SQLite database from Python using `sqlite3`\n- Use `pandas.read_sql()` to pull query results directly into DataFrames\n- Write aggregation queries: GROUP BY, HAVING, window functions\n- Perform JOIN operations and understand when to use SQL vs Pandas\n- Load the SO 2025 dataset into SQLite and answer analytical questions with SQL\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Setup\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import sqlite3\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams['figure.dpi'] = 110\n\nDATASET_URL = 'https://raw.githubusercontent.com/timothy-watt/python-for-ai-ml/main/data/so_survey_2025_curated.csv'\nDB_PATH     = '/tmp/so2025.db'\n\n# Load SO 2025 and create SQLite database\ndf_raw = pd.read_csv(DATASET_URL)\ndf = df_raw.copy()\ndf = df.dropna(subset=['ConvertedCompYearly'])\ndf['ConvertedCompYearly'] = pd.to_numeric(df['ConvertedCompYearly'], errors='coerce')\nQ1, Q3 = df['ConvertedCompYearly'].quantile([0.25, 0.75])\nIQR = Q3 - Q1\ndf = df[\n    (df['ConvertedCompYearly'] >= max(Q1 - 3*IQR, 5_000)) &\n    (df['ConvertedCompYearly'] <= min(Q3 + 3*IQR, 600_000))\n].copy()\nif 'YearsCodePro' in df.columns:\n    df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\ndf['uses_python'] = df.get('LanguageHaveWorkedWith', pd.Series(dtype=str)).str.contains('Python', na=False).astype(int)\ndf['log_salary']  = np.log(df['ConvertedCompYearly'])\ndf['primary_role'] = df.get('DevType', pd.Series(dtype=str)).str.split(';').str[0].str.strip()\ndf = df.reset_index(drop=True)\n\n# Write to SQLite\nconn = sqlite3.connect(DB_PATH)\nkeep_cols = [c for c in ['Country', 'EdLevel', 'RemoteWork', 'YearsCodePro',\n                          'ConvertedCompYearly', 'log_salary',\n                          'uses_python', 'primary_role'] if c in df.columns]\ndf[keep_cols].to_sql('developers', conn, if_exists='replace', index=False)\nprint(f'Loaded {len(df):,} rows into SQLite table: developers')\nprint(f'Columns: {keep_cols}')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## E.1 -- Core SQL: SELECT, WHERE, GROUP BY\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# E.1.1 -- Basic SELECT and aggregation\n\nqueries = {\n    'Count by country (top 10)': \"\"\"\n        SELECT Country,\n               COUNT(*)                          AS respondents,\n               ROUND(AVG(ConvertedCompYearly), 0) AS avg_salary,\n               ROUND(MIN(ConvertedCompYearly), 0) AS min_salary,\n               ROUND(MAX(ConvertedCompYearly), 0) AS max_salary\n        FROM   developers\n        WHERE  Country IS NOT NULL\n        GROUP  BY Country\n        HAVING COUNT(*) >= 50\n        ORDER  BY avg_salary DESC\n        LIMIT  10\n    \"\"\",\n    'Python premium by education': \"\"\"\n        SELECT EdLevel,\n               uses_python,\n               COUNT(*)                          AS n,\n               ROUND(AVG(ConvertedCompYearly), 0) AS avg_salary\n        FROM   developers\n        WHERE  EdLevel IS NOT NULL\n        GROUP  BY EdLevel, uses_python\n        ORDER  BY EdLevel, uses_python\n    \"\"\",\n}\n\nfor title, sql in queries.items():\n    print(f'=== {title} ===')\n    result = pd.read_sql(sql, conn)\n    print(result.to_string(index=False))\n    print()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# E.1.2 -- Window functions: rank within group\n# Window functions compute a value for each row relative to a group\n# without collapsing the rows (unlike GROUP BY)\n\nsql_window = \"\"\"\n    SELECT Country,\n           primary_role,\n           ROUND(AVG(ConvertedCompYearly), 0) AS avg_salary,\n           COUNT(*)                           AS n,\n           RANK() OVER (\n               PARTITION BY Country\n               ORDER BY AVG(ConvertedCompYearly) DESC\n           ) AS rank_in_country\n    FROM   developers\n    WHERE  Country IN ('United States of America', 'United Kingdom of Great Britain and Northern Ireland',\n                       'Germany', 'India')\n      AND  primary_role IS NOT NULL\n    GROUP  BY Country, primary_role\n    HAVING COUNT(*) >= 10\n    ORDER  BY Country, rank_in_country\n\"\"\"\n\nwindow_df = pd.read_sql(sql_window, conn)\n# Show top 3 roles per country\ntop3 = window_df[window_df['rank_in_country'] <= 3]\nprint('Top 3 highest-paying roles per country (SQL RANK window function):')\nprint(top3.to_string(index=False))\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# E.1.3 -- SQL vs Pandas: when to use each\n\n# The same query in both -- compare syntax and output\n\n# SQL version\nsql_agg = \"\"\"\n    SELECT   Country,\n             COUNT(*)                           AS n,\n             ROUND(AVG(ConvertedCompYearly), 0) AS avg_salary,\n             ROUND(AVG(uses_python) * 100, 1)   AS pct_python\n    FROM     developers\n    WHERE    Country IS NOT NULL\n    GROUP BY Country\n    HAVING   COUNT(*) >= 100\n    ORDER BY avg_salary DESC\n    LIMIT    8\n\"\"\"\nsql_result = pd.read_sql(sql_agg, conn)\n\n# Equivalent Pandas version\npandas_result = (\n    df[df['Country'].notna()]\n    .groupby('Country')\n    .agg(\n        n=('ConvertedCompYearly', 'count'),\n        avg_salary=('ConvertedCompYearly', 'mean'),\n        pct_python=('uses_python', 'mean')\n    )\n    .query('n >= 100')\n    .sort_values('avg_salary', ascending=False)\n    .head(8)\n    .round({'avg_salary': 0, 'pct_python': 3})\n    .reset_index()\n)\npandas_result['pct_python'] = (pandas_result['pct_python'] * 100).round(1)\n\nprint('SQL result:')\nprint(sql_result.to_string(index=False))\nprint()\nprint('Pandas result (equivalent):')\nprint(pandas_result.to_string(index=False))\n\nprint()\nprint('When to use SQL:')\nprint('  - Data lives in a database (most production data does)')\nprint('  - You need only a subset of rows -- SQL filters before loading')\nprint('  - Complex joins across multiple tables')\nprint('  - Window functions are concise and readable')\nprint()\nprint('When to use Pandas:')\nprint('  - Data is already in memory / a CSV file')\nprint('  - Complex reshaping, melting, pivoting')\nprint('  - Chaining with visualisation or ML pipelines')\nprint('  - The full dataset fits comfortably in RAM')\n\nconn.close()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## E.2 -- SQL Quick Reference\n\n```sql\n-- Basic structure\nSELECT col1, col2, AGG(col3)\nFROM   table\nWHERE  condition           -- filter rows BEFORE grouping\nGROUP  BY col1, col2\nHAVING AGG(col3) > value   -- filter AFTER grouping\nORDER  BY col1 DESC\nLIMIT  10;\n\n-- Common aggregate functions\nCOUNT(*)  COUNT(col)  SUM(col)  AVG(col)  MIN(col)  MAX(col)\n\n-- JOIN types\nINNER JOIN  -- only matching rows in both tables\nLEFT JOIN   -- all rows from left, NULLs where no match in right\nFULL JOIN   -- all rows from both (not in SQLite)\n\n-- Window functions\nRANK()       OVER (PARTITION BY col ORDER BY col2)\nROW_NUMBER() OVER (PARTITION BY col ORDER BY col2)\nLAG(col, 1)  OVER (ORDER BY date_col)   -- previous row value\nSUM(col)     OVER (PARTITION BY col ORDER BY date_col)  -- running total\n\n-- Subqueries\nSELECT * FROM table WHERE col IN (SELECT col FROM other_table WHERE ...)\n\n-- CTEs (Common Table Expressions) -- readable alternative to subqueries\nWITH ranked AS (\n    SELECT *, RANK() OVER (PARTITION BY Country ORDER BY Salary DESC) AS rnk\n    FROM developers\n)\nSELECT * FROM ranked WHERE rnk <= 3;\n```\n\n---\n\n*End of Appendix E -- Python for AI/ML*  \n[![Back to TOC](https://img.shields.io/badge/Back_to-Table_of_Contents-1B3A5C?style=flat-square)](https://colab.research.google.com/github/timothy-watt/python-for-ai-ml/blob/main/Python_for_AIML_TOC.ipynb)\n"
    }
  ]
}