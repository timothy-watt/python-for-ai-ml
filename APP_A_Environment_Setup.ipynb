{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Appendix A -- Python Environment Setup\n## *Python for AI/ML: A Complete Learning Journey*\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timothy-watt/python-for-ai-ml/blob/main/APP_A_Environment_Setup.ipynb)\n&nbsp;&nbsp;[![Back to TOC](https://img.shields.io/badge/Back_to-Table_of_Contents-1B3A5C?style=flat-square)](https://colab.research.google.com/github/timothy-watt/python-for-ai-ml/blob/main/Python_for_AIML_TOC.ipynb)\n\n---\n\nThis appendix covers everything you need to run the book's notebooks locally\non your own machine, and to set up a professional Python development environment\nfor AI/ML work beyond Colab.\n\n**Sections:**\n\n- A.1 -- Local Python setup with `conda` and `venv`\n- A.2 -- Reproducing the Colab environment locally\n- A.3 -- GPU setup for PyTorch (NVIDIA CUDA)\n- A.4 -- Managing dependencies with `requirements.txt` and `environment.yml`\n- A.5 -- VS Code setup for notebook development\n- A.6 -- Version pinning and reproducibility\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## A.1 -- Local Python Setup\n\nThe book uses Google Colab, which provides a managed Python environment.\nFor local development, you have two main options: **conda** (recommended for\ndata science) and **venv** (Python's built-in virtual environment tool).\n\n### Why use a virtual environment at all?\n\nWithout virtual environments, all projects share a single Python installation.\nProject A needs `numpy==1.24`, Project B needs `numpy==2.0` -- they cannot\ncoexist in the same installation. Virtual environments solve this by giving\neach project its own isolated package space.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# A.1.1 -- Detect the current environment\n# Run this cell to see what Python and key packages are installed\n\nimport sys\nimport subprocess\n\nprint(f'Python executable: {sys.executable}')\nprint(f'Python version:    {sys.version}')\n\npackages = ['numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn',\n            'scipy', 'torch', 'transformers', 'shap']\n\nprint()\nprint(f'{\"Package\":<20} {\"Version\":<15} {\"Status\"}')\nprint('-' * 45)\nfor pkg in packages:\n    try:\n        mod = __import__(pkg if pkg != 'sklearn' else 'sklearn')\n        ver = getattr(mod, '__version__', 'unknown')\n        print(f'{pkg:<20} {ver:<15} installed')\n    except ImportError:\n        print(f'{pkg:<20} {\"\":15} NOT INSTALLED')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## A.2 -- Conda Setup (Recommended)\n\n[Miniconda](https://docs.conda.io/en/latest/miniconda.html) is the minimal\ninstaller for conda. Install it, then use the commands below.\n\n```bash\n# 1. Create a new environment named 'pyaiml' with Python 3.11\nconda create -n pyaiml python=3.11 -y\n\n# 2. Activate it\nconda activate pyaiml\n\n# 3. Install the core data science stack\nconda install numpy pandas matplotlib seaborn scipy scikit-learn jupyter -y\n\n# 4. Install PyTorch (CPU version -- see A.3 for GPU)\nconda install pytorch cpuonly -c pytorch -y\n\n# 5. Install remaining packages with pip\npip install transformers datasets accelerate shap lime nltk plotly\n\n# 6. Register the environment as a Jupyter kernel\npip install ipykernel\npython -m ipykernel install --user --name pyaiml --display-name 'Python (pyaiml)'\n\n# 7. Launch Jupyter\njupyter notebook\n```\n\nTo deactivate the environment when you are done: `conda deactivate`\n\n---\n\n## A.3 -- venv Setup (Built-in, no conda required)\n\n```bash\n# 1. Create a virtual environment in a folder called .venv\npython3.11 -m venv .venv\n\n# 2. Activate it (macOS/Linux)\nsource .venv/bin/activate\n# On Windows:\n# .venv\\Scripts\\activate\n\n# 3. Upgrade pip first\npip install --upgrade pip\n\n# 4. Install everything\npip install numpy pandas matplotlib seaborn scipy scikit-learn\npip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\npip install transformers datasets accelerate shap lime nltk plotly jupyter\n```\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## A.4 -- GPU Setup for PyTorch (NVIDIA CUDA)\n\nGPU training is required for Chapter 7 fine-tuning at scale and highly\nrecommended for Chapter 8. The setup depends on your NVIDIA driver version.\n\n### Step 1: Check your NVIDIA driver\n\n```bash\nnvidia-smi\n```\n\nThe output shows your driver version and the maximum CUDA version it supports.\n\n### Step 2: Install the matching PyTorch build\n\nGo to [pytorch.org/get-started/locally](https://pytorch.org/get-started/locally/)\nand use the selector to generate the correct install command for your CUDA version.\n\nExample for CUDA 12.1:\n```bash\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n```\n\n### Step 3: Verify GPU is detected\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# A.4.1 -- Verify PyTorch GPU setup\nimport torch\n\nprint(f'PyTorch version:    {torch.__version__}')\nprint(f'CUDA available:     {torch.cuda.is_available()}')\n\nif torch.cuda.is_available():\n    print(f'CUDA version:       {torch.version.cuda}')\n    print(f'GPU count:          {torch.cuda.device_count()}')\n    for i in range(torch.cuda.device_count()):\n        props = torch.cuda.get_device_properties(i)\n        print(f'GPU {i}:             {props.name}')\n        print(f'  Memory:           {props.total_memory / 1e9:.1f} GB')\n        print(f'  CUDA capability:  {props.major}.{props.minor}')\nelse:\n    print('No GPU detected -- running on CPU')\n    print('For Colab GPU: Runtime -> Change runtime type -> T4 GPU')\n    print('For local GPU: see A.4 instructions above')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## A.5 -- Managing Dependencies\n\n### requirements.txt (pip)\n\nLock exact package versions so your environment is reproducible:\n\n```bash\n# Save current environment\npip freeze > requirements.txt\n\n# Recreate on another machine\npip install -r requirements.txt\n```\n\n### environment.yml (conda)\n\n```bash\n# Save current conda environment\nconda env export > environment.yml\n\n# Recreate on another machine\nconda env create -f environment.yml\n```\n\n### Pinned requirements.txt for this book\n\nThe cell below prints a `requirements.txt` for the exact versions used\nin this book's Colab environment:\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# A.5.1 -- Generate requirements.txt for this book\nimport importlib\n\nbook_packages = {\n    'numpy':          'numpy',\n    'pandas':         'pandas',\n    'matplotlib':     'matplotlib',\n    'seaborn':        'seaborn',\n    'scipy':          'scipy',\n    'scikit-learn':   'sklearn',\n    'torch':          'torch',\n    'transformers':   'transformers',\n    'datasets':       'datasets',\n    'accelerate':     'accelerate',\n    'shap':           'shap',\n    'nltk':           'nltk',\n    'plotly':         'plotly',\n}\n\nprint('# requirements.txt for Python for AI/ML')\nprint('# Generated from Colab environment')\nprint()\nfor pkg_name, import_name in book_packages.items():\n    try:\n        mod = importlib.import_module(import_name)\n        ver = getattr(mod, '__version__', 'unknown')\n        print(f'{pkg_name}=={ver}')\n    except ImportError:\n        print(f'# {pkg_name}  -- not installed in this environment')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## A.6 -- VS Code Setup for Notebook Development\n\nVS Code with the Python and Jupyter extensions provides a full notebook\nexperience locally with better debugging, git integration, and variable\ninspection than the browser-based Jupyter interface.\n\n**Setup steps:**\n\n1. Install [VS Code](https://code.visualstudio.com/)\n2. Install extensions: **Python** (Microsoft) and **Jupyter** (Microsoft)\n3. Open a `.ipynb` file -- VS Code handles it natively\n4. Select your kernel: click the kernel selector top-right â†’ choose `pyaiml`\n   (or whichever environment you created in A.2/A.3)\n\n**Recommended additional extensions:**\n\n- **GitLens** -- enhanced git history and blame annotations\n- **Pylance** -- fast type checking and autocomplete\n- **Black Formatter** -- auto-format Python code on save\n- **Rainbow CSV** -- colour-coded CSV file preview\n\n**Useful VS Code settings for data science** (add to `settings.json`):\n\n```json\n{\n    \"editor.formatOnSave\": true,\n    \"python.formatting.provider\": \"black\",\n    \"jupyter.askForKernelRestart\": false,\n    \"notebook.lineNumbers\": \"on\",\n    \"editor.rulers\": [88]\n}\n```\n\n---\n\n*End of Appendix A -- Python for AI/ML*  \n[![Back to TOC](https://img.shields.io/badge/Back_to-Table_of_Contents-1B3A5C?style=flat-square)](https://colab.research.google.com/github/timothy-watt/python-for-ai-ml/blob/main/Python_for_AIML_TOC.ipynb)\n"
    }
  ]
}