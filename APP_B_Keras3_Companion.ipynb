{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Appendix B -- Keras 3 Companion\n## *Python for AI/ML: A Complete Learning Journey*\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/timothy-watt/python-for-ai-ml/blob/main/APP_B_Keras3_Companion.ipynb)\n&nbsp;&nbsp;[![Back to TOC](https://img.shields.io/badge/Back_to-Table_of_Contents-1B3A5C?style=flat-square)](https://colab.research.google.com/github/timothy-watt/python-for-ai-ml/blob/main/Python_for_AIML_TOC.ipynb)\n\n---\n\n> **Prerequisites:** Chapter 7 (Deep Learning with PyTorch)\n\nThis appendix rebuilds the Chapter 7 neural networks using **Keras 3**,\nthe multi-backend high-level API that runs on PyTorch, TensorFlow, or JAX.\n\nThe goal is not to replace Chapter 7 -- it is to show how the same concepts\nmap to a higher-level API. Once you understand the PyTorch training loop,\nthe Keras abstractions become transparent rather than magical.\n\n**What you will build:**\n\n- The same salary regression MLP from Chapter 7 in 20 lines of Keras\n- The same Python usage classifier from Chapter 7 in Keras\n- Side-by-side comparison: PyTorch explicit vs Keras concise\n- When to use each: decision guide\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## Setup\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import subprocess\nsubprocess.run(['pip', 'install', 'keras', '-q'], check=False)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport keras\nfrom keras import layers, callbacks\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score, accuracy_score, mean_absolute_error\n\nprint(f'Keras version: {keras.__version__}')\nprint(f'Keras backend: {keras.backend.backend()}')\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams['figure.dpi'] = 110\n\nDATASET_URL  = 'https://raw.githubusercontent.com/timothy-watt/python-for-ai-ml/main/data/so_survey_2025_curated.csv'\nRANDOM_STATE = 42\nkeras.utils.set_random_seed(RANDOM_STATE)\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Load and prepare SO 2025 data -- same as Chapter 7\ndf_raw = pd.read_csv(DATASET_URL)\ndf = df_raw.copy()\ndf = df.dropna(subset=['ConvertedCompYearly'])\ndf['ConvertedCompYearly'] = pd.to_numeric(df['ConvertedCompYearly'], errors='coerce')\nQ1, Q3 = df['ConvertedCompYearly'].quantile([0.25, 0.75])\nIQR = Q3 - Q1\ndf = df[\n    (df['ConvertedCompYearly'] >= max(Q1 - 3*IQR, 5_000)) &\n    (df['ConvertedCompYearly'] <= min(Q3 + 3*IQR, 600_000))\n].copy()\nif 'YearsCodePro' in df.columns:\n    df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n    df['YearsCodePro'] = df['YearsCodePro'].fillna(df['YearsCodePro'].median())\ndf['uses_python'] = df.get('LanguageHaveWorkedWith', pd.Series(dtype=str)).str.contains('Python', na=False).astype(int)\ndf['uses_sql']    = df.get('LanguageHaveWorkedWith', pd.Series(dtype=str)).str.contains('SQL', na=False).astype(int)\ndf['uses_js']     = df.get('LanguageHaveWorkedWith', pd.Series(dtype=str)).str.contains('JavaScript', na=False).astype(int)\ndf['uses_ai']     = df.get('AIToolCurrently', pd.Series(dtype=str)).notna().astype(int)\ndf['log_salary']  = np.log(df['ConvertedCompYearly'])\ndf = df.reset_index(drop=True)\n\nfeature_cols = [c for c in ['YearsCodePro', 'uses_python', 'uses_sql', 'uses_js', 'uses_ai']\n                if c in df.columns]\nX_raw = df[feature_cols].copy()\nfor col in feature_cols:\n    med = X_raw[col].median()\n    X_raw[col] = X_raw[col].fillna(med if pd.notna(med) else 0)\ny = df['log_salary'].values\n\nX_tr, X_te, y_tr, y_te = train_test_split(X_raw.values, y, test_size=0.2, random_state=RANDOM_STATE)\nscaler = StandardScaler()\nX_tr_sc = scaler.fit_transform(X_tr)\nX_te_sc = scaler.transform(X_te)\n\nprint(f'Dataset ready: {len(df):,} rows')\nprint(f'Train: {len(X_tr_sc):,}  Test: {len(X_te_sc):,}  Features: {len(feature_cols)}')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## B.1 -- The Same MLP in Keras: Side-by-Side Comparison\n\nThe table below maps every PyTorch concept from Chapter 7 to its Keras equivalent.\nRead this before looking at the code -- it makes the mapping explicit.\n\n| PyTorch (Chapter 7) | Keras (Appendix B) |\n|---------------------|--------------------|\n| `class MyNet(nn.Module)` | `keras.Sequential([...])` |\n| `nn.Linear(in, out)` | `layers.Dense(out)` |\n| `nn.ReLU()` | `layers.Activation('relu')` or `activation='relu'` |\n| `nn.BatchNorm1d(n)` | `layers.BatchNormalization()` |\n| `nn.Dropout(p)` | `layers.Dropout(p)` |\n| `optim.AdamW(...)` | `keras.optimizers.AdamW(...)` |\n| `nn.MSELoss()` | `loss='mse'` in `model.compile()` |\n| Manual training loop | `model.fit(X, y, ...)` |\n| `model.eval()` | Automatic during `model.predict()` |\n| `torch.no_grad()` | Automatic during inference |\n| `model.state_dict()` | `model.save_weights(path)` |\n\nThe key difference: Keras hides the training loop inside `model.fit()`.\nThis is more concise but less transparent. Chapter 7's explicit loop\ngives you full control and understanding. Keras gives you speed of development.\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# B.1.1 -- Salary regression MLP in Keras\n# Compare this directly with the SalaryMLP class in Chapter 7\n\ninput_dim = X_tr_sc.shape[1]\n\n# In Keras, the model is defined declaratively as a list of layers\n# No explicit forward() method -- Keras infers it from the layer order\nsalary_model = keras.Sequential([\n    # Input layer specifies the feature dimension\n    layers.Input(shape=(input_dim,)),\n\n    # Hidden block 1: Linear -> BatchNorm -> ReLU -> Dropout\n    layers.Dense(128),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(0.3),\n\n    # Hidden block 2\n    layers.Dense(64),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(0.3),\n\n    # Hidden block 3\n    layers.Dense(32),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(0.3),\n\n    # Output layer: single neuron, no activation (regression)\n    layers.Dense(1),\n])\n\n# compile() sets the loss function and optimiser\n# This replaces: criterion = nn.MSELoss() and optimizer = optim.AdamW(...)\nsalary_model.compile(\n    optimizer=keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n    loss='mse',\n    metrics=['mae']\n)\n\nsalary_model.summary()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# B.1.2 -- Train with model.fit()\n# This replaces the entire manual training loop from Chapter 7\n\n# Callbacks replace manual logic in the training loop:\n# EarlyStopping = best-weight checkpointing + stopping\n# ReduceLROnPlateau = learning rate scheduler\nearly_stop = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    restore_best_weights=True,   # equivalent to saving best_weights in Ch7\n    verbose=0\n)\nreduce_lr = callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.5, patience=5, verbose=0\n)\n\nhistory = salary_model.fit(\n    X_tr_sc, y_tr,\n    validation_data=(X_te_sc, y_te),\n    epochs=60,\n    batch_size=256,\n    callbacks=[early_stop, reduce_lr],\n    verbose=0    # suppress per-epoch output; we plot the history below\n)\n\nprint(f'Trained for {len(history.history[\"loss\"])} epochs '\n      f'(early stopping at {early_stop.stopped_epoch or 60})')\n\n# Evaluate\ny_pred_log = salary_model.predict(X_te_sc, verbose=0).flatten()\ny_pred_usd = np.exp(y_pred_log)\ny_true_usd = np.exp(y_te)\n\nr2  = r2_score(y_te, y_pred_log)\nmae = mean_absolute_error(y_true_usd, y_pred_usd)\nprint(f'Test R^2:  {r2:.4f}')\nprint(f'Test MAE:  ${mae:,.0f}')\n\n# Plot training history -- history.history is a dict of metric lists\nfig, ax = plt.subplots(figsize=(9, 4))\nax.plot(history.history['loss'],     '#E8722A', linewidth=2, label='Train loss')\nax.plot(history.history['val_loss'], '#2E75B6', linewidth=2, label='Val loss')\nax.set_xlabel('Epoch')\nax.set_ylabel('MSE Loss')\nax.set_title(f'Keras Salary MLP Training Curves  (R^2={r2:.3f}, MAE=${mae/1000:.1f}k)')\nax.legend()\nplt.tight_layout()\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# B.1.3 -- Python usage classifier in Keras\n\nclf_cols = [c for c in ['YearsCodePro', 'ConvertedCompYearly',\n                         'uses_sql', 'uses_js', 'uses_ai'] if c in df.columns]\nX_clf = df[clf_cols].copy()\nfor col in clf_cols:\n    med = X_clf[col].median()\n    X_clf[col] = X_clf[col].fillna(med if pd.notna(med) else 0)\ny_clf = df['uses_python'].values.astype(np.float32)\n\nX_tc, X_ec, y_tc, y_ec = train_test_split(\n    X_clf.values, y_clf, test_size=0.2, random_state=RANDOM_STATE, stratify=y_clf\n)\nclf_sc  = StandardScaler()\nX_tc_sc = clf_sc.fit_transform(X_tc)\nX_ec_sc = clf_sc.transform(X_ec)\n\nclf_model = keras.Sequential([\n    layers.Input(shape=(X_tc_sc.shape[1],)),\n    layers.Dense(64),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(0.2),\n    layers.Dense(32),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(0.2),\n    # sigmoid output for binary classification\n    # In PyTorch we used BCEWithLogitsLoss (raw logit + sigmoid in one op)\n    # In Keras we use sigmoid activation + binary_crossentropy loss\n    layers.Dense(1, activation='sigmoid'),\n])\n\nclf_model.compile(\n    optimizer=keras.optimizers.AdamW(learning_rate=1e-3),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nclf_history = clf_model.fit(\n    X_tc_sc, y_tc,\n    validation_data=(X_ec_sc, y_ec),\n    epochs=50, batch_size=256,\n    callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=8,\n                                        restore_best_weights=True, verbose=0)],\n    verbose=0\n)\n\ny_pred_clf = (clf_model.predict(X_ec_sc, verbose=0).flatten() >= 0.5).astype(int)\nacc = accuracy_score(y_ec, y_pred_clf)\nprint(f'Classifier accuracy: {acc:.4f}  ({acc*100:.1f}%)')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## B.2 -- When to Use PyTorch vs Keras\n\nBoth frameworks are production-grade. The choice depends on your use case:\n\n| Situation | Recommendation |\n|-----------|----------------|\n| Learning how neural networks work | **PyTorch** -- explicit loop teaches the mechanics |\n| Rapid prototyping, standard architectures | **Keras** -- less boilerplate |\n| Research, custom training procedures | **PyTorch** -- full control |\n| Multi-backend (run on TF, PyTorch, or JAX) | **Keras 3** |\n| Production deployment on TensorFlow Serving | **Keras on TF backend** |\n| HuggingFace ecosystem, pre-trained transformers | **PyTorch** |\n| Academic papers, reproducibility | **PyTorch** (dominant in research) |\n\nThe honest answer for most practitioners: **learn PyTorch first** (as this book does),\nthen use Keras when speed of development matters more than transparency.\n\n---\n\n*End of Appendix B -- Python for AI/ML*  \n[![Back to TOC](https://img.shields.io/badge/Back_to-Table_of_Contents-1B3A5C?style=flat-square)](https://colab.research.google.com/github/timothy-watt/python-for-ai-ml/blob/main/Python_for_AIML_TOC.ipynb)\n"
    }
  ]
}